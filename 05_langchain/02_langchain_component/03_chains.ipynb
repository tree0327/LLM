{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 워크플로우 구성 - Chains & Memory (체인과 메모리)\n",
    "\n",
    "**LCEL(LangChain Expression Language)**을 사용하여 여러 작업을 연결하고, 복잡한 프로세스를 처리합니다.  \n",
    "또한 대화의 맥락(Context)을 기억하는 **Memory** 기능도 실습합니다.\n",
    "\n",
    "**학습 목표:**\n",
    "1. **Simple Chain:** 프롬프트, 모델, 파서를 연결하여 기본적인 LLM 파이프라인 만들기\n",
    "2. **Sequential Chain:** 하나의 체인 출력을 다음 체인의 입력으로 연결하여 순차적 작업 수행하기\n",
    "3. **Router Chain (Conditional):** 입력 내용에 따라 적절한 체인을 선택하여 실행하는 분기 로직 구현하기\n",
    "4. **Memory:** 대화 내역(History)을 기억하고 문맥을 이해하는 챗봇 체인 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 환경 설정 (Environment Setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain langchain-openai langchain-community -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"openai_key\")\n",
    "\n",
    "# LangSmith 설정 (선택)\n",
    "os.environ[\"LANGSMITH_TRACING\"] = 'true'\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = 'https://api.smith.langchain.com'\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = 'skn23-langchain'\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"langsmith_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "### 2. Simple Chain (기본 체인)\n",
    "\n",
    "가장 기본적인 LCEL 패턴입니다.\n",
    "`Prompt(입력 구성) -> Model(생성) -> Parser(후처리)` 순서로 연결합니다.\n",
    "\n",
    "```python\n",
    "chain = prompt | model | output_parser\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 구성 요소 준비\n",
    "prompt = PromptTemplate.from_template('{country}의 수도는 어디인가요?')\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. 체인 연결 (Pipe 연산자 사용)\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# 3. 실행\n",
    "print(chain.invoke({'country': '대한민국'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "### 3. Sequential Chain (순차 체인)\n",
    "\n",
    "하나의 체인 실행 결과를 다음 체인의 입력으로 넘겨줍니다.\n",
    "예시: `영어 문장 번역` -> `번역된 문장 요약`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 체인: 영어 -> 한글 번역\n",
    "prompt1 = PromptTemplate.from_template('다음 내용을 한글로 번역하세요.\\n\\n{eng_text}')\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# 두 번째 체인: 한글 -> 요약\n",
    "# 입력 변수명이 {kor_text}로 되어있음. chain1의 출력을 여기에 매핑해줘야 함.\n",
    "prompt2 = PromptTemplate.from_template('다음 내용을 한 문장으로 요약하세요.\\n\\n{kor_text}')\n",
    "chain2 = prompt2 | llm | StrOutputParser()\n",
    "\n",
    "# 전체 체인 연결\n",
    "# chain1의 출력(문자열)이 chain2의 첫 번째 인자(kor_text)로 자동 전달됨 (인자가 1개일 때)\n",
    "full_chain = chain1 | chain2\n",
    "\n",
    "eng_input = \"\"\"\n",
    "One limitation of LLMs is their lack of contextual information (e.g., access to some specific documents or emails). \n",
    "You can combat this by giving LLMs access to the specific external data.\n",
    "For this, you first need to load the external data with a document loader. \n",
    "LangChain provides a variety of loaders for different types of documents ranging from PDFs and emails to websites and YouTube videos.\n",
    "\"\"\"\n",
    "\n",
    "print(\"[원본]:\", eng_input.strip()[:50], \"...\")\n",
    "result = full_chain.invoke({'eng_text': eng_input})\n",
    "print(\"\\n[요약 결과]:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "### 4. Router Chain (분기 체인)\n",
    "\n",
    "입력된 질문의 **주제**나 **의도**에 따라 다른 체인을 실행하고 싶을 때 사용합니다.\n",
    "예: 수학 문제는 `Math Chain`, 일상 대화는 `Chat Chain`으로 분기.\n",
    "\n",
    "- `RunnableBranch`: 조건에 따라 분기 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "# 1. 분기될 체인들 정의\n",
    "# 수학 문제용 체인\n",
    "math_chain = (\n",
    "    PromptTemplate.from_template(\"다음 수식을 단계별로 풀이해 주세요:\\n{question}\")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 일반 대화용 체인\n",
    "general_chain = (\n",
    "    PromptTemplate.from_template(\"친절하게 답변해 주세요:\\n{question}\")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 2. 분기 조건 함수\n",
    "def is_math_question(input_dict: dict) -> bool:\n",
    "    q = input_dict.get('question', '')\n",
    "    return any(keyword in q for keyword in ['계산', '수식', '더하기', '곱하기', '+', '*', 'calc'])\n",
    "\n",
    "# 3. Branch 연결\n",
    "branch_chain = RunnableBranch(\n",
    "    (is_math_question, math_chain),  # (조건 함수, 실행할 체인)\n",
    "    general_chain                    # 조건이 안 맞을 때 실행할 기본 체인\n",
    ")\n",
    "\n",
    "# 테스트\n",
    "print(\"1. 수학 문제:\")\n",
    "print(branch_chain.invoke({'question': '125 * 3 + 50 계산해줘'}))\n",
    "\n",
    "print(\"\\n2. 일반 대화:\")\n",
    "print(branch_chain.invoke({'question': '오늘 점심 메뉴 추천해줘'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "### 5. Memory With Chain (대화 맥락 유지)\n",
    "\n",
    "LLM은 기본적으로 **무상태(Stateless)**입니다. 이전 대화 내용을 기억하지 못합니다.\n",
    "대화 내역을 저장하고 프롬프트에 주입해주는 `RunnableWithMessageHistory`를 사용하여 기억을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# 1. 메모리 저장소 (세션 ID별로 대화 기록 저장)\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 2. 프롬프트 정의 (MessagesPlaceholder로 히스토리 들어갈 자리 마련)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 도움이 되는 챗봇입니다.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),  # 대화 내역이 여기에 주입됨\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# 3. 체인 생성\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 4. 히스토리 기능 래핑\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "# 5. 대화 실행 (세션 ID: user1)\n",
    "config = {\"configurable\": {\"session_id\": \"user1\"}}\n",
    "\n",
    "response1 = chain_with_history.invoke(\n",
    "    {\"question\": \"내 이름은 김철수야. 기억해줘.\"}, \n",
    "    config=config\n",
    ")\n",
    "print(\"AI:\", response1)\n",
    "\n",
    "response2 = chain_with_history.invoke(\n",
    "    {\"question\": \"내 이름이 모니?\"}, \n",
    "    config=config\n",
    ")\n",
    "print(\"AI:\", response2)\n",
    "\n",
    "# 6. 다른 세션 (세션 ID: user2) - 기억 못함 확인\n",
    "config2 = {\"configurable\": {\"session_id\": \"user2\"}}\n",
    "response3 = chain_with_history.invoke(\n",
    "    {\"question\": \"내 이름이 모니?\"}, \n",
    "    config=config2\n",
    ")\n",
    "print(\"AI (user2):\", response3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}