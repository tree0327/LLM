# LLM이란?

## 1. 아키텍트의 시선: LLM이란 무엇인가?

LLM(거대 언어 모델)을 한마디로 정의하면 **"확률적 이어 말하기 기계"**입니다.

많은 사람들이 LLM을 "지능을 가진 인격체"로 착각하지만, 아키텍트는 이를 냉정하게 **"다음에 올 단어를 예측하는 함수"**로 바라봐야 합니다.

### 핵심 비유: 앵무새 vs 도서관 사서

*   **일반적인 오해 (인격체)**: 질문을 이해하고 고민해서 답변하는 존재.
*   **아키텍트의 이해 (확률 통계)**: 도서관의 모든 책을 읽은 후, "이런 질문 뒤에는 통계적으로 이런 단어가 오더라"를 계산해서 내뱉는 기계.

## 2. 작동 원리 (Mechanism)

### 2.1 Next Token Prediction (다음 토큰 예측)

LLM은 문장을 한 번에 완성하지 않습니다. 한 글자(토큰)씩 순서대로 생성합니다.

**예시:** "대한민국의 수도는" 이라는 입력이 들어오면 LLM은 내부적으로 확률을 계산합니다.

1.  "서울" (확률 85%)
2.  "부산" (확률 5%)
3.  "평양" (확률 2%)
4.  ...

가장 확률이 높은 "서울"을 선택합니다.
그 다음 "대한민국의 수도는 서울" 뒤에 올 단어를 또 예측합니다. ("입니다", "이다" 등)

이 단순한 작업의 반복이 우리가 보는 "지능적인 답변"의 실체입니다.

### 2.2 파라미터 (Parameters)

*   **정의**: 모델 내부의 신경망 연결 강도 (사람 뇌의 시냅스와 유사).
*   **역할**: 지식과 언어 패턴을 저장하는 공간.
*   **규모**: GPT-4 같은 모델은 수천억~수조 개의 파라미터를 가집니다. 파라미터가 많을수록 더 복잡한 패턴(논리, 추론 등)을 기억할 수 있습니다.

### 2.3 학습 (Training) vs 추론 (Inference)

건축에 비유하자면 다음과 같습니다.

1.  **사전 학습 (Pre-training)**:
    *   **비유**: 건축가가 대학에서 10년 동안 전 세계의 모든 건축 서적을 읽고 공부하는 과정.
    *   **특징**: 엄청난 비용과 시간이 듭니다. (수백억 원, 수천 개의 GPU)
    *   **결과**: "기반 모델 (Foundation Model)" 탄생. (예: GPT-4 Base)

2.  **추론 (Inference)**:
    *   **비유**: 공부를 마친 건축가가 실제로 도면을 그리는 과정.
    *   **특징**: 우리가 사용하는 단계입니다. 질문(Input)을 던지면 답변(Output)을 생성합니다.
    *   **비용**: 실행할 때마다 비용이 발생합니다. (API 요금)

## 3. 왜 거짓말을 하는가? (Hallucination)

LLM은 "사실(Fact)"을 말하는 기계가 아니라, "그럴듯한 말(Probable Word)"을 만드는 기계이기 때문입니다.

*   만약 문맥상 거짓말이 나올 확률이 가장 높다면, LLM은 태연하게 거짓말을 합니다.
*   아키텍트는 이를 통제하기 위해 **RAG (검색 증강 생성)** 같은 기술을 사용해야 합니다. (3단계에서 다룰 예정)

## 4. 코드 설계도: 확률 확인하기

우리가 사용하는 API는 완성된 텍스트만 주지만, 내부적으로는 확률을 계산하고 있습니다. 이를 확인하는 상상 코드입니다.

```python
# 개념적인 수도 코드 (Pseudo-code)

model = load_llm("gpt-4")
input_text = "사과는 맛있는"

# 1. 다음에 올 단어들의 확률 계산
probabilities = model.predict_next_token_probabilities(input_text)

# 2. 확률 분포 출력
# {
#   "과일": 0.7,
#   "음식": 0.1,
#   "빨간색": 0.05,
#   ...
# }

# 3. 선택 (Sampling)
# 일반적으로 가장 높은 확률(Greedy)을 선택하거나, 
# 약간의 무작위성(Temperature)을 섞어서 선택함.
next_word = select_token(probabilities, temperature=0.7)

print(f"다음 단어: {next_word}")
```

## 5. 심화 질문

> **"LLM은 텍스트를 이해하는 것일까, 아니면 통계적으로 흉내 내는 것일까?"**
>
> 이 철학적인 질문은 **AI 서비스의 한계점**을 명확히 하는 데 중요합니다. 이해하지 못한다고 가정하고 시스템을 설계해야 안전합니다.
