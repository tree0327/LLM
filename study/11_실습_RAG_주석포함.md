# RAG ì „ ê³¼ì • ì‹¤ìŠµ (ì£¼ì„ í¬í•¨ ë²„ì „) ğŸ“

ì•„í‚¤í…íŠ¸ë‹˜, `study.ipynb` íŒŒì¼ì´ ê°±ì‹ ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ì´ ì½”ë“œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”!
ê° ì¤„ë§ˆë‹¤ ìƒì„¸í•œ ì„¤ëª…ì„ ë‹¬ì•„ë‘ì—ˆìŠµë‹ˆë‹¤.

```python
# ==========================================
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (ê³µêµ¬í•¨ ì—´ê¸°)
# ==========================================
import os
from dotenv import load_dotenv

# ë³´ì•ˆì„ ìœ„í•´ API í‚¤ ì •ë³´ê°€ ë‹´ê¸´ .env íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
load_dotenv()

# ì‚¬ìš©í•  ë„êµ¬ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from langchain_openai import ChatOpenAI, OpenAIEmbeddings  # AI ëª¨ë¸ & ë²ˆì—­ê¸°
from langchain_text_splitters import RecursiveCharacterTextSplitter  # ë¬¸ì„œë¥¼ ìë¥´ëŠ” ì¹¼
from langchain_chroma import Chroma  # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ (ë„ì„œê´€)
from langchain_core.documents import Document  # í…ìŠ¤íŠ¸ë¥¼ ê°ì‹¸ëŠ” í¬ì¥ì§€

# ==========================================
# 2. ë°ì´í„° ì¤€ë¹„ (Load)
# ==========================================
# ì‹¤ìŠµì„ ìœ„í•´ ê°€ì§œ 'ì‚¬ê·œ' ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë§Œë“­ë‹ˆë‹¤.
raw_text = """
[ì£¼ì‹íšŒì‚¬ ì‚¬ìê°œ ì‚¬ê·œ]
ì œ 1ì¡° (ëª©ì ) ë³¸ ê·œì •ì€ ì‚¬ìê°œ ì£¼ì‹íšŒì‚¬ì˜ ë³µì§€ë¥¼ ê·œì •í•œë‹¤.
ì œ 2ì¡° (ê·¼ë¬´ì‹œê°„) ê·¼ë¬´ì‹œê°„ì€ ì˜¤ì „ 10ì‹œë¶€í„° ì˜¤í›„ 5ì‹œê¹Œì§€ë¡œ í•œë‹¤. (ì£¼ 35ì‹œê°„)
ì œ 3ì¡° (ë³µì§€ í¬ì¸íŠ¸) ì „ ì§ì›ì€ ë§¤ë…„ 1ì›” 1ì¼, ë³µì§€ í¬ì¸íŠ¸ 300ë§Œ ì›ì„ ì§€ê¸‰ë°›ëŠ”ë‹¤.
ì œ 4ì¡° (íœ´ê°€) ì—°ì°¨ëŠ” ë¬´ì œí•œìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ë‹¤ë§Œ, 2ì£¼ ì´ìƒ ì—°ì† ì‚¬ìš© ì‹œ íŒ€ì¥ ìŠ¹ì¸ì´ í•„ìš”í•˜ë‹¤.
ì œ 5ì¡° (ê°„ì‹) íƒ•ë¹„ì‹¤ì—ëŠ” í•­ìƒ ëª¬ìŠ¤í„° ì—ë„ˆì§€ ë“œë§í¬ì™€ ë§ˆì¹´ë¡±ì„ êµ¬ë¹„í•´ì•¼ í•œë‹¤.
"""

# ==========================================
# 3. í…ìŠ¤íŠ¸ ë¶„í•  (Split)
# ==========================================
# ë¬¸ì„œë¥¼ AIê°€ ì½ê¸° ì¢‹ê²Œ(Context Window) ì‘ì€ ë‹¨ìœ„ë¡œ ìë¦…ë‹ˆë‹¤.
splitter = RecursiveCharacterTextSplitter(
    chunk_size=100,    # 100ê¸€ì ë‹¨ìœ„ë¡œ ìë¦„
    chunk_overlap=20   # ë¬¸ë§¥ì´ ëŠê¸°ì§€ ì•Šê²Œ 20ê¸€ìì”© ê²¹ì³ì„œ ìë¦„ (ì§ì†Œí¼ì¦)
)

# create_documents: ë‹¨ìˆœ ê¸€ìê°€ ì•„ë‹ˆë¼ 'Document ê°ì²´'ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
chunks = splitter.create_documents([raw_text])

print(f"ì´ {len(chunks)}ê°œì˜ ì¡°ê° ìƒì„± ì™„ë£Œ.")

# ==========================================
# 4. ì„ë² ë”© ë° ì €ì¥ (Embed & Store)
# ==========================================
# Chroma DBë¥¼ ë©”ëª¨ë¦¬ì— ìƒì„±í•˜ê³  ë¬¸ì„œë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
vector_db = Chroma.from_documents(
    documents=chunks,                 # ìª¼ê°œì§„ ë¬¸ì„œ ì¡°ê°ë“¤
    embedding=OpenAIEmbeddings()      # ì‚¬ìš©í•  ë²ˆì—­ê¸° (ê¸€ì -> ìˆ«ì ë²¡í„°)
)
print("ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ.")

# ==========================================
# 5. ì§ˆë¬¸ ë° ê²€ìƒ‰ (Retrieve)
# ==========================================
query = "íšŒì‚¬ ë³µì§€ í¬ì¸íŠ¸ ì–¼ë§ˆë‚˜ ì¤˜?"

# similarity_search: ì§ˆë¬¸ê³¼ ì˜ë¯¸ê°€ ê°€ì¥ ê°€ê¹Œìš´(ê±°ë¦¬ê°€ ì§§ì€) ë¬¸ì„œë¥¼ ì°¾ì•„ì˜µë‹ˆë‹¤.
# k=2: ìƒìœ„ 2ê°œë§Œ ê°€ì ¸ì™€ë¼
retrieved_docs = vector_db.similarity_search(query, k=2)

print(f"\n[ì§ˆë¬¸]: {query}")
print(f"[ì°¾ì€ ë¬¸ì„œ]: {retrieved_docs[0].page_content}")

# ==========================================
# 6. ë‹µë³€ ìƒì„± (Generate)
# ==========================================
# temperature=0: ì°½ì˜ì„±ì„ ë„ê³  ì‚¬ì‹¤ëŒ€ë¡œë§Œ ë§í•˜ê²Œ ì„¤ì •
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# RAGì˜ í•µì‹¬: ì°¾ì€ ë¬¸ì„œ(retrieved_docs)ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë¼ì›Œ ë„£ìŠµë‹ˆë‹¤.
prompt = f"""
ë‹¹ì‹ ì€ ì¸ì‚¬íŒ€ AIì…ë‹ˆë‹¤.
ì•„ë˜ [ì°¸ê³  ë¬¸ì„œ]ë¥¼ ë³´ê³  ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

[ì°¸ê³  ë¬¸ì„œ]
{retrieved_docs[0].page_content}

ì§ˆë¬¸: {query}
"""

response = llm.invoke(prompt)

print(f"\n[AI ë‹µë³€]: {response.content}")
```
